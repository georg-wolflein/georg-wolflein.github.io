@STRING{UNDERREVIEW = {under review}}
@STRING{JIMAGING = {Journal of Imaging}}
@STRING{JIMAGING_SHORT = {J. Imaging}}
@STRING{CANCERS = {Cancers}}
@STRING{CANCERS_SHORT = {Cancers}}
@STRING{OSF = {Open Science Foundation}}
@STRING{WACV = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}}
@STRING{WACV_SHORT = {WACV}}

@inproceedings{woelflein2023wacv,
  title     = {{HoechstGAN}: Virtual Lymphocyte Staining Using Generative Adversarial Networks},
  author    = {W\"{o}lflein, Georg and Um, In Hwa and Harrison, David J and Arandjelovi\'{c}, Ognjen},
  author+an = {1=highlight},
  booktitle = WACV,
  abbr      = WACV_SHORT,
  month     = {1},
  year      = {2023},
  preview   = {hoechstgan.png},
  code      = {https://github.com/georg-wolflein/hoechstgan},
  abstract  = {The presence and density of specific types of immune cells are important to understand a patient's immune response to cancer. However, immunofluorescence staining required to identify T cell subtypes is expensive, timeconsuming, and rarely performed in clinical settings. We present a framework to virtually stain Hoechst images (which are cheap and widespread) with both CD3 and CD8 to identify T cell subtypes in clear cell renal cell carcinoma using generative adversarial networks. Our proposed method jointly learns both staining tasks, incentivising the network to incorporate mutually beneficial information from each task. We devise a novel metric to quantify the virtual staining quality, and use it to evaluate our method.},
  keywords  = {conference,paper}
}

@article{defilippis2022,
  title        = {Use of high-plex data reveals novel insights into the tumour microenvironment of clear cell renal cell carcinoma},
  author       = {De Filippis, Raffaele and W\"{o}lflein, Georg and Um, In Hwa and Caie, Peter D and Warren, Sarah and White, Andrew and Suen, Elizabeth and To, Emily and Arandjelovi\'{c}, Ognjen and Harrison, David J},
  author+an    = {1=first; 2=first, highlight},
  firstauthors = {2},
  journal      = UNDERREVIEW,
  year         = {2022},
  preview      = {highplex.png},
  keywords     = {journal,paper}
}

@article{wolflein2021jimaging,
  title          = {Determining Chess Game State from an Image},
  author         = {W\"olflein, Georg and Arandjelovi\'c, Ognjen},
  author+an      = {1=highlight},
  journal        = JIMAGING,
  abbr           = JIMAGING_SHORT,
  volume         = {7},
  year           = {2021},
  month          = {6},
  number         = {6},
  article-number = {94},
  url            = {https://www.mdpi.com/2313-433X/7/6/94},
  arxiv_         = {2104.14963},
  doi            = {10.3390/jimaging7060094},
  keywords       = {journal,paper},
  code           = {https://github.com/georg-wolflein/chesscog},
  website        = {https://www.chesscog.com},
  abstract       = {Identifying the configuration of chess pieces from an image of a chessboard is a problem in computer vision that has not yet been solved accurately. However, it is important for helping amateur chess players improve their games by facilitating automatic computer analysis without the overhead of manually entering the pieces. Current approaches are limited by the lack of large datasets and are not designed to adapt to unseen chess sets. This paper puts forth a new dataset synthesised from a 3D model that is an order of magnitude larger than existing ones. Trained on this dataset, a novel end-to-end chess recognition system is presented that combines traditional computer vision techniques with deep learning. It localises the chessboard using a RANSAC-based algorithm that computes a projective transformation of the board onto a regular grid. Using two convolutional neural networks, it then predicts an occupancy mask for the squares in the warped image and finally classifies the pieces. The described system achieves an error rate of 0.23\% per square on the test set, 28 times better than the current state of the art. Further, a few-shot transfer learning approach is developed that is able to adapt the inference system to a previously unseen chess set using just two photos of the starting position, obtaining a per-square accuracy of 99.83\% on images of that new chess set. The code, dataset, and trained models are made available online.},
  selected       = {true},
  preview        = {chesscog.png},
  pdf            = {https://www.mdpi.com/2313-433X/7/6/94/pdf},
  blog           = {/blog/2021/chesscog}
}

@misc{wolflein2021osf,
  title        = {Dataset of Rendered Chess Game State Images},
  author       = {W\"olflein, Georg and Arandjelovi\'c, Ognjen},
  author+an    = {1=highlight},
  url          = {https://osf.io/xf3ka},
  website      = {https://osf.io/xf3ka},
  doi          = {10.17605/OSF.IO/XF3KA},
  organization = OSF,
  year         = {2021},
  month        = {5},
  keywords     = {dataset},
  preview      = {chesscog-dataset.png},
  abstract     = {This dataset contains 4,888 synthetic images of chess game states that occurred in games played by Magnus Carlsen. The images were rendered in Blender at different angles and lighting conditions.}
}

@thesis{wolflein2021msci,
  title       = {Determining Chess Game State From an Image Using Machine Learning},
  author      = {W\"olflein, Georg},
  author+an   = {1=highlight},
  advisor     = {Arandjelovi\'c, Ognjen},
  institution = {University of St Andrews},
  year        = {2021},
  month       = {1},
  badge       = {MSci},
  preview     = {chesscog.png},
  pdf         = {https://github.com/georg-wolflein/chesscog-report/raw/master/report.pdf},
  code        = {https://github.com/georg-wolflein/chesscog},
  url         = {https://www.chesscog.com},
  website     = {https://www.chesscog.com},
  blog        = {/blog/2021/chesscog},
  abstract    = {Identifying the configuration of chess pieces from an image of a chessboard is a problem in computer vision that has not yet been solved accurately. However, it is important for helping amateur chess players improve their games by facilitating automatic computer analysis without the overhead of manually entering the pieces. Current approaches are limited by the lack of large datasets and are not designed to adapt to unseen chess sets. This project puts forth a new dataset synthesised from a 3D model that is two orders of magnitude larger than existing ones. Trained on this dataset, a novel end-to-end chess recognition system is presented that combines traditional computer vision techniques with deep learning. It localises the chessboard using a RANSAC-based algorithm that computes a projective transformation of the board onto a regular grid. Using two convolutional neural networks, it then predicts an occupancy mask for the squares in the warped image and finally classifies the pieces. The described system achieves an error rate of 0.23\% per square on the test set, 28 times better than the current state of the art. Further, a one-shot transfer learning approach is developed that is able to adapt the inference system to a previously unseen chess set using just two photos of the starting position, obtaining a per-square accuracy of 99.83\% on images of that new chess set. Inference takes less than half a second on a GPU and about two seconds on a CPU. The feasibility of the system is demonstrated in an interactive web app available at https://www.chesscog.com.}
}

@thesis{wolflein2020bsc,
  title       = {Freeing Neural Training Through Surfing},
  author      = {W\"olflein, Georg},
  author+an   = {1=highlight},
  advisor     = {Weir, Michael},
  institution = {University of St Andrews},
  year        = {2020},
  month       = {4},
  badge       = {BSc},
  preview     = {neural-surfing.png},
  pdf         = {https://github.com/georg-wolflein/neural-surfing/raw/master/report/report.pdf},
  code        = {https://github.com/georg-wolflein/neural-surfing},
  url         = {https://github.com/georg-wolflein/neural-surfing},
  abstract    = {Gradient methods based on backpropagation are widely used in training multilayer feedforward neural networks. However, such algorithms often converge to suboptimal weight configurations known as local minima. This report presents a novel minimal example of the local minimum problem with only three training samples and demonstrates its suitability for investigating and resolving said problem by analysing its mathematical properties and conditions leading to the failure of conventional training regimes. A different perspective for training neural networks is introduced that concerns itself with neural spaces and is applied to study the local minimum example.This gives rise to the concept of setting intermediate subgoals during training which is demonstrated to be a viable and effective means of overcoming the local minimum problem. The versatility of subgoal-based approaches is highlighted by showing their potential for training more generally. An example of a subgoal-based training regime using sampling and an adaptive clothoid for establishing a goal-connecting path is suggested as a proof of concept for further research. In addition, this project includes the design and implementation of a software framework for monitoring the performance of different neural training algorithms on a given problem simultaneously and in real time. This framework can be used to reproduce the findings of how classical algorithms fail to find the global minimum in the aforementioned example.}
}
<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Georg Wölflein </title> <meta name="author" content="Georg Wölflein"> <meta name="description" content="Georg Wölflein's homepage. "> <meta name="keywords" content="deep-learning, ai, ml, artificial-intelligence, machine-learning, digital-pathology"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%94%A5&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://georg.woelflein.eu/"> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/Georg_Wolflein_CV.pdf" target="_blank"> cv </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Georg</span> Wölflein </h1> <p class="desc">PhD student in computer vision / deep learning</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?2e54f0dd4d9821bd94ca9875cc2afa2b" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>I’m Georg, an AI Engineer at <a href="https://synagen.ai" target="\_blank" rel="external nofollow noopener">Synagen AI</a> and part-time researcher at <a href="https://jnkather.github.io" target="\_blank" rel="external nofollow noopener">Kather Lab</a> (<a href="https://www.tu-dresden.de" target="\_blank" rel="external nofollow noopener">TU Dresden</a>). Before this, I was a PhD student at the <a href="https://www.st-andrews.ac.uk" target="\_blank" rel="external nofollow noopener">University of St Andrews</a>, advised by <a href="https://www.st-andrews.ac.uk/computer-science/people/oa7/" target="\_blank" rel="external nofollow noopener">Ognjen Arandjelović</a> My current focus is on developing LLM agents for healthcare. Previously, my research centred on computer vision and deep learning for computational pathology, with an emphasis on weakly supervised biomarker prediction from histopathology images.</p> <p>Feel free to reach out via email!</p> <div class="social-links"> <a href="mailto:%67%65%6F%72%67@%77%6F%65%6C%66%6C%65%69%6E.%64%65"><i class="fas fa-envelope fa-lg"></i> email</a> <a href="https://scholar.google.com/citations?user=XTpEX9oAAAAJ" target="_blank" title="Google Scholar" rel="external nofollow noopener"><i class="ai ai-google-scholar ai-lg"></i> scholar</a> <a href="https://github.com/georg-wolflein" target="_blank" title="GitHub" rel="external nofollow noopener"><i class="fab fa-github fa-lg"></i> github</a> <a href="https://www.linkedin.com/in/georg-wolflein" target="_blank" title="LinkedIn" rel="external nofollow noopener"><i class="fab fa-linkedin fa-lg"></i> linkedin</a> </div> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">May 16, 2025</th> <td> <a href="https://georg.woelflein.eu/toolmaker">ToolMaker</a> has been accepted at <a href="https://2025.aclweb.org" rel="external nofollow noopener" target="_blank">ACL 2025</a>! </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 01, 2025</th> <td> <a href="https://arxiv.org/abs/2411.13623" rel="external nofollow noopener" target="_blank">COBRA</a> has been accepted at <a href="https://cvpr.thecvf.com/Conferences/2025" rel="external nofollow noopener" target="_blank">CVPR 2025</a>! </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 20, 2025</th> <td> I will be giving a <a href="https://events.scads.ai/event/98/#4-llm-agents-for-autonomously" rel="external nofollow noopener" target="_blank">talk</a> at <a href="https://scads.ai" rel="external nofollow noopener" target="_blank">SCADS.AI</a> on LLM agents for autonomous tool creation </td> </tr> <tr> <th scope="row" style="width: 20%">May 01, 2024</th> <td> I will be doing a research internship at Google in London this summer. </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 05, 2024</th> <td> I gave a <a href="https://warwick.ac.uk/fac/cross_fac/tia/seminars/seminars-23-24/#georg_wolflein" target="\_blank" rel="external nofollow noopener">talk</a> at the Warwick Tissue Image Analytics (TIA) Centre about self-supervised feature extractors for pathology slide classification. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <p> Please refer to the <a href="/publications/">publications tab</a> or <a href="https://scholar.google.com/citations?user=&amp;hl=en" target="_blank" rel="external nofollow noopener">Google Scholar</a> for a complete list. </p> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">J. Imaging</abbr> <a href="https://www.mdpi.com/2313-433X/7/6/94" target="_blank" rel="external nofollow noopener"> <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/chesscog.png" loading="eager" alt="chesscog.png" style="max-width: 100%; height: auto;"> </a> </div> <div id="wolflein2021determining" class="col-sm-8"> <div class="title">Determining Chess Game State from an Image</div> <div class="author"> <em>Georg Wölflein</em> and Ognjen Arandjelović </div> <div class="periodical"> <em>Journal of Imaging</em>, Jun 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2104.14963" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a> <a href="https://www.mdpi.com/2313-433X/7/6/94/pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">PDF</a> <a href="/blog/2021/chesscog" class="btn btn-sm z-depth-0" role="button">Blog</a> <a href="https://github.com/georg-wolflein/chesscog" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> </div> <div class="abstract hidden"> <p>Identifying the configuration of chess pieces from an image of a chessboard is a problem in computer vision that has not yet been solved accurately. However, it is important for helping amateur chess players improve their games by facilitating automatic computer analysis without the overhead of manually entering the pieces. Current approaches are limited by the lack of large datasets and are not designed to adapt to unseen chess sets. This paper puts forth a new dataset synthesised from a 3D model that is an order of magnitude larger than existing ones. Trained on this dataset, a novel end-to-end chess recognition system is presented that combines traditional computer vision techniques with deep learning. It localises the chessboard using a RANSAC-based algorithm that computes a projective transformation of the board onto a regular grid. Using two convolutional neural networks, it then predicts an occupancy mask for the squares in the warped image and finally classifies the pieces. The described system achieves an error rate of 0.23% per square on the test set, 28 times better than the current state of the art. Further, a few-shot transfer learning approach is developed that is able to adapt the inference system to a previously unseen chess set using just two photos of the starting position, obtaining a per-square accuracy of 99.83% on images of that new chess set. The code, dataset, and trained models are made available online.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">WACV</abbr> <a href="https://openaccess.thecvf.com/content/WACV2023/html/Wolflein_HoechstGAN_Virtual_Lymphocyte_Staining_Using_Generative_Adversarial_Networks_WACV_2023_paper.html" target="_blank" rel="external nofollow noopener"> <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/hoechstgan.png" loading="eager" alt="hoechstgan.png" style="max-width: 100%; height: auto;"> </a> </div> <div id="wolflein2023hoechstgan" class="col-sm-8"> <div class="title">HoechstGAN: Virtual Lymphocyte Staining Using Generative Adversarial Networks</div> <div class="author"> <em>Georg Wölflein</em>, In Hwa Um, David J Harrison, and Ognjen Arandjelović </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, Jan 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2210.06909" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a> <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Wolflein_HoechstGAN_Virtual_Lymphocyte_Staining_Using_Generative_Adversarial_Networks_WACV_2023_paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">PDF</a> <a href="https://github.com/georg-wolflein/hoechstgan" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> <a href="/assets/pdf/hoechstgan_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a> <a href="https://www.youtube.com/watch?v=XrhwqRNjtv4" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Video</a> <a href="https://georg.woelflein.eu/hoechstgan" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>The presence and density of specific types of immune cells are important to understand a patient’s immune response to cancer. However, immunofluorescence staining required to identify T cell subtypes is expensive, timeconsuming, and rarely performed in clinical settings. We present a framework to virtually stain Hoechst images (which are cheap and widespread) with both CD3 and CD8 to identify T cell subtypes in clear cell renal cell carcinoma using generative adversarial networks. Our proposed method jointly learns both staining tasks, incentivising the network to incorporate mutually beneficial information from each task. We devise a novel metric to quantify the virtual staining quality, and use it to evaluate our method.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <a href="https://arxiv.org/abs/2305.10552" target="_blank" rel="external nofollow noopener"> <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/das-mil.png" loading="eager" alt="das-mil.png" style="max-width: 100%; height: auto;"> </a> </div> <div id="wolflein2023deep" class="col-sm-8"> <div class="title">Deep Multiple Instance Learning with Distance-Aware Self-Attention</div> <div class="author"> <em>Georg Wölflein</em>, Lucie Charlotte Magister, Pietro Liò, David J Harrison, and Ognjen Arandjelović </div> <div class="periodical"> May 2023 </div> <div class="periodical"> under review </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2305.10552" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a> <a href="https://arxiv.org/pdf/2305.10552.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">PDF</a> <a href="https://github.com/georg-wolflein/das-mil" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> </div> <div class="abstract hidden"> <p>Traditional supervised learning tasks require a label for every instance in the training set, but in many real-world applications, labels are only available for collections (bags) of instances. This problem setting, known as multiple instance learning (MIL), is particularly relevant in the medical domain, where high-resolution images are split into smaller patches, but labels apply to the image as a whole. Recent MIL models are able to capture correspondences between patches by employing self-attention, allowing them to weigh each patch differently based on all other patches in the bag. However, these approaches still do not consider the relative spatial relationships between patches within the larger image, which is especially important in computational pathology. To this end, we introduce a novel MIL model with distance-aware self-attention (DAS-MIL), which explicitly takes into account relative spatial information when modelling the interactions between patches. Unlike existing relative position representations for self-attention which are discrete, our approach introduces continuous distance-dependent terms into the computation of the attention weights, and is the first to apply relative position representations in the context of MIL. We evaluate our model on a custom MNIST-based MIL dataset that requires the consideration of relative spatial information, as well as on CAMELYON16, a publicly available cancer metastasis detection dataset, where we achieve a test AUROC score of 0.91. On both datasets, our model outperforms existing MIL approaches that employ absolute positional encodings, as well as existing relative position representation schemes applied to MIL. Our code is available at https://anonymous.4open.science/r/das-mil.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ECCV</abbr> <a href="https://arxiv.org/abs/2311.11772v4" target="_blank" rel="external nofollow noopener"> <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/histaug.png" loading="eager" alt="histaug.png" style="max-width: 100%; height: auto;"> </a> </div> <div id="wolflein2023good" class="col-sm-8"> <div class="title">A Good Feature Extractor Is All You Need for Weakly Supervised Pathology Slide Classification</div> <div class="author"> <em>Georg Wölflein</em>, Dyke Ferber, Asier Rabasco Meneghetti, Omar S. M. El Nahhas, Daniel Truhn, Zunamys I. Carrero, David J. Harrison, Ognjen Arandjelović, and Jakob Nikolas Kather </div> <div class="periodical"> <em>In European Conference on Computer Vision (ECCV)</em>, Sep 2024 </div> <div class="periodical"> BioImage Computing Workshop (oral) </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2311.11772" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a> <a href="https://arxiv.org/pdf/2311.11772v4.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">PDF</a> <a href="https://github.com/georg-wolflein/good-features" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> <a href="https://www.youtube.com/watch?v=Tst4XtaT9RE" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Video</a> <a href="https://georg.woelflein.eu/good-features" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Stain normalisation is thought to be a crucial preprocessing step in computational pathology pipelines. We question this belief in the context of weakly supervised whole slide image classification, motivated by the emergence of powerful feature extractors trained using self-supervised learning on diverse pathology datasets. To this end, we performed the most comprehensive evaluation of publicly available pathology feature extractors to date, involving more than 8,000 training runs across nine tasks, five datasets, three downstream architectures, and various preprocessing setups. Notably, we find that omitting stain normalisation and image augmentations does not compromise downstream slide-level classification performance, while incurring substantial savings in memory and compute. Using a new evaluation metric that facilitates relative downstream performance comparison, we identify the best publicly available extractors, and show that their latent spaces are remarkably robust to variations in stain and augmentations like rotation. Contrary to previous patch-level benchmarking studies, our approach emphasises clinical relevance by focusing on slide-level biomarker prediction tasks in a weakly supervised setting with external validation cohorts. Our findings stand to streamline digital pathology workflows by minimising preprocessing needs and informing the selection of feature extractors.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ACL</abbr> <a href="https://arxiv.org/abs/2502.11705" target="_blank" rel="external nofollow noopener"> <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/toolmaker.png" loading="eager" alt="toolmaker.png" style="max-width: 100%; height: auto;"> </a> </div> <div id="wolflein2025toolmaker" class="col-sm-8"> <div class="title">LLM Agents Making Agent Tools</div> <div class="author"> <em>Georg Wölflein</em>, Dyke Ferber, Daniel Truhn, Ognjen Arandjelović, and Jakob Nikolas Kather </div> <div class="periodical"> <em>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</em>, Jul 2025 </div> <div class="periodical"> accepted </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2502.11705" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a> <a href="https://arxiv.org/pdf/2502.11705.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">PDF</a> <a href="https://github.com/KatherLab/ToolMaker" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> <a href="https://georg.woelflein.eu/toolmaker" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Tool use has turned large language models (LLMs) into powerful agents that can perform complex multi-step tasks by dynamically utilising external software components. However, these tools must be implemented in advance by human developers, hindering the applicability of LLM agents in domains which demand large numbers of highly specialised tools, like in life sciences and medicine. Motivated by the growing trend of scientific studies accompanied by public code repositories, we propose ToolMaker, a novel agentic framework that autonomously transforms papers with code into LLM-compatible tools. Given a short task description and a repository URL, ToolMaker autonomously installs required dependencies and generates code to perform the task, using a closed-loop self-correction mechanism to iteratively diagnose and rectify errors. To evaluate our approach, we introduce a benchmark comprising 15 diverse and complex computational tasks spanning both medical and non-medical domains with over 100 unit tests to objectively assess tool correctness and robustness. ToolMaker correctly implements 80% of the tasks, substantially outperforming current state-of-the-art software engineering agents. ToolMaker therefore is a step towards fully autonomous agent-based scientific workflows.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%67%65%6F%72%67@%77%6F%65%6C%66%6C%65%69%6E.%64%65" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/georg-wolflein" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/georg-wolflein" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://scholar.google.com/citations?user=XTpEX9oAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://twitter.com/gwoelflein" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Georg Wölflein. Powered by <a href="http://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with the <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="external nofollow noopener">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>